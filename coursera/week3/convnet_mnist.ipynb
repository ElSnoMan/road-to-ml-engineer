{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('road-to-ml-engineer-pxbKeJd0-py3.8': venv)",
   "metadata": {
    "interpreter": {
     "hash": "d916e02d396d23918371d70adfc43f0721d38ce5b5df02b7f176b7d3f3b35e95"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Improve the MNIST Model using a Convolutional Nueral Network\n",
    "\n",
    "Now that I know about ConvNets and how they improve the performance and accuracy of a Computer Vision model, I need to apply on my own to the MNIST Dataset\n",
    "\n",
    "### Challenge\n",
    "* [Notebook for this Lab](https://www.coursera.org/learn/introduction-tensorflow/ungradedLab/QDkCT/lab)\n",
    "* [Google Colab Notebook](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%203%20-%20Convolutions/Exercise%203%20-%20Question.ipynb)\n",
    "\n",
    "For your exercise see if you can improve MNIST to `99.8% accuracy` or more using only a `single convolutional layer` and a `single MaxPooling 2D`.\n",
    "\n",
    "* You should stop training once the accuracy goes above this amount.\n",
    "* It should happen in less than 20 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your layers.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load Dataset \"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define Callback to prevent wasted epochs/compute and overfitting \"\"\"\n",
    "class AccuracyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if logs.get('accuracy') > 0.998:\n",
    "            print('\\nReached 99.8% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = AccuracyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Preprocess images to work with a ConvNet \"\"\"\n",
    "train_images = train_images.reshape(60000, 28, 28, 1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 64)        640       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 10816)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               1384576   \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 1,386,506\nTrainable params: 1,386,506\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Define Model \"\"\"\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.1326 - accuracy: 0.9604\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0454 - accuracy: 0.9860\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.0269 - accuracy: 0.9916\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0181 - accuracy: 0.9946\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Reached 99.8% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0051 - accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Compile and Fit\n",
    "\n",
    "* Get above 99.8% accuracy in under 20 epochs\n",
    "\"\"\"\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n0.9983500242233276\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)\n",
    "print(history.history['accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each other"
   ]
  }
 ]
}