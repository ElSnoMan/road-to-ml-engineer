# Natural Language Processing with Tensorflow

## Week 1 - Intro to Tokenizer and NLP

* Text to sequences
* Tokenizing and given words numeric values
* Dealing with non-indexed words
* Padding


## Week 2 - Embeddings and Text Classification

* IMDB Movie Reviews to do Sentiment Analysis
    * [Google Colab Notebook](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%202%20-%20Lesson%201.ipynb)

* Sarcasm Dataset to do Sentiment Analysis
    * Challenge: Tune the hyperparameters to get 90%+ accuracy without a sharp increase in the loss function
    * [Google Colab Notebook](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%202%20-%20Lesson%202.ipynb)


## Week 3 - RNNs for NLP

* LSTMs
* GRUs
* RNNs
* ConvNets
* Proper Preprocessing
* Combine layers (like a Convolution then feeding into an LSTM)

[Google Colab Notebook](https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/NLP%20Course%20-%20Week%203%20Exercise%20Answer.ipynb)


## Week 4 - From Classification to Text Generation

Dealing with really large datasets, I used Google Colab with GPU for better performance.

* Word-based RNNs
* Character-based RNNs
    * [Google Colab Notebook](https://colab.research.google.com/drive/1sAAXpkFB0-9c6JeaVrtnbjl5pqaAs5LR)
